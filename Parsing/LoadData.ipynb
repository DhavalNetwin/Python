{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadCSVData(path):    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = ReadCSVData('E:\\Dhaval\\Elastic Search\\Python\\E-Book\\Data File\\highstoragesystem-data-for-energy-optimization\\HRSS_normal_optimized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sampleColumn(hsNData):\n",
    "    result = []\n",
    "    cnt = 0\n",
    "    for index, value in enumerate(hsNData['Timestamp']):\n",
    "        if index == 0:\n",
    "            result.append(cnt)\n",
    "        elif index == len(hsNData['Timestamp'])-1:\n",
    "            result.append(cnt)\n",
    "        elif hsNData['Timestamp'][index] - hsNData['Timestamp'][index - 1] < 0:        \n",
    "            result.append(cnt+1)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            result.append(cnt)\n",
    "    hsNData['sampleNum'] = result\n",
    "    return hsNData, set(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = add_sampleColumn(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleDataperSample(Sampledata, noOfSamples, noOfTimeStamps, attributes):  \n",
    "    data_sampled=np.zeros([noOfSamples, noOfTimeStamps, attributes]) # strictly speaking w/o the first 3 columns! only the 18 attributes\n",
    "    time_steps= np.arange(noOfTimeStamps)*0.05 \n",
    "    time_steps\n",
    "    data_org= Sampledata\n",
    "    time_index = np.zeros([noOfTimeStamps,])\n",
    "    time_lower = np.zeros([noOfTimeStamps,])\n",
    "    time_upper = np.zeros([noOfTimeStamps,])\n",
    "    alpha = np.zeros([noOfTimeStamps,])\n",
    "    for i in range(noOfTimeStamps):\n",
    "        time_index[i] = np.sum(((np.array(data_org['Timestamp'])- time_steps[i])<=0)) -1 \n",
    "    time_index.astype(int)\n",
    "    time_lower = np.array(data_org['Timestamp'].loc[time_index]) #there should be no nans\n",
    "    time_upper = np.array(data_org['Timestamp'].loc[time_index+1]) # last may contain nans, to be catched later\n",
    "    alpha = (time_upper - time_steps)/(time_upper-time_lower)\n",
    "    data_values=np.array(data_org)\n",
    "\n",
    "    # rewrite in matrix form, will be faster\n",
    "    for i in range(noOfTimeStamps):\n",
    "        for j in range(attributes):\n",
    "            tt=(time_index[i]+1).astype(int)\n",
    "            if (time_index[i]+1)>len(data_org)-1:\n",
    "                tt=len(data_org)-1\n",
    "            data_sampled[1,i,j]=alpha[i]*data_values[time_index[i].astype(int),j] + (1-alpha[i])*data_values[tt,j]\n",
    "    return pd.DataFrame(data_sampled[1,:,:])\n",
    "    # finally catch NaNs, set to zero\n",
    "    # interate through samples\n",
    "    # noOfSamples no. of samples, noOfTimeStamps no. of time stamps and attributes no. of attributes\n",
    "    # len(data_org)-1 no of time stamps in original data/ no of rows per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data2 = resampleDataperSample(Data[0], max(Data[1]), 241, len(Data[0].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resample_AllSamples(data,samples,_noOfTimeStamps):\n",
    "    MainDataFrame = pd.DataFrame(columns=np.arange(len(data.columns)))\n",
    "    for i in range(samples):\n",
    "        data2 = data.loc[data['sampleNum'] == i]\n",
    "        data2.index = np.arange(len(data2))\n",
    "        tempdataframe = resampleDataperSample(data2, samples-1, _noOfTimeStamps, len(data2.columns))\n",
    "        MainDataFrame = MainDataFrame.append(tempdataframe, ignore_index=False, verify_integrity=False, sort=None)\n",
    "    MainDataFrame.index=np.arange(len(MainDataFrame))\n",
    "    MainDataFrame = MainDataFrame.dropna(axis=0, how='all')\n",
    "    return MainDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snehal.Waman\\python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "FinalData = Resample_AllSamples(Data[0],max(Data[1])+1,241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
